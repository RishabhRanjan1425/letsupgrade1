{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNgvfd/ZaZo6/yR9TsQ8CCt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RishabhRanjan1425/letsupgrade1/blob/main/Rishabhproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "_a29kZmDx-M-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# loading Data\n",
        "dataset = (r'C:\\Users\\DELL\\Desktop\\datasets\\Capstone_project')"
      ],
      "metadata": {
        "id": "N1Jn-Yu7yQsj"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# setting image size and batch size\n",
        "img_size = (180, 180)\n",
        "batch_size = 32"
      ],
      "metadata": {
        "id": "ZVcI7ioxy0WG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Augmentation\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1./255,\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode='nearest'\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)"
      ],
      "metadata": {
        "id": "my7o7kxYy1ty"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the list of image files\n",
        "covid_images = [os.path.join(dataset, 'COVID', img) for img in os.listdir(os.path.join(dataset, 'COVID'))]\n",
        "non_covid_images = [os.path.join(dataset, 'non-COVID', img) for img in os.listdir(os.path.join(dataset, 'non-COVID'))]"
      ],
      "metadata": {
        "id": "LjgukQy5y6Uq"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split the data into train and validation sets\n",
        "covid_train, covid_val = train_test_split(covid_images, test_size=0.2, random_state=42)\n",
        "non_covid_train, non_covid_val = train_test_split(non_covid_images, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "GVi_e0sly-0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = pd.DataFrame({'filename': covid_train + non_covid_train, 'class': ['covid']*len(covid_train) + ['non-covid']*len(non_covid_train)})\n",
        "val_df = pd.DataFrame({'filename': covid_val + non_covid_val, 'class': ['covid']*len(covid_val) + ['non-covid']*len(non_covid_val)})"
      ],
      "metadata": {
        "id": "VzUoUHBszEJ9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will be resizing the image to same size"
      ],
      "metadata": {
        "id": "viTq2_1VzPry"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create train and validation generators\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    train_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=img_size,#here in the place of target_size we are resizing the images that can fix the all image sizes in to same sizes\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "\n",
        ")\n",
        "\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "    val_df,\n",
        "    x_col='filename',\n",
        "    y_col='class',\n",
        "    target_size=img_size,#here in the place of target_size we are resizing the images that can fix the all image sizes in to same sizes\n",
        "    batch_size=batch_size,\n",
        "    class_mode='binary',\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "c7nqXzJlzXaj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing librarys which is used to build architeture\n",
        "from tensorflow.keras.applications import ResNet50\n",
        "from tensorflow.keras import layers, models,callbacks"
      ],
      "metadata": {
        "id": "ZanXot2gzqE-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "res50 = ResNet50(input_shape = (180, 180, 3), weights = 'imagenet', include_top = False)"
      ],
      "metadata": {
        "id": "if9W9nl2ztOO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for layer in vgg16.layers:\n",
        "  layer.trainable = False"
      ],
      "metadata": {
        "id": "PRS-CYEUzwqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization"
      ],
      "metadata": {
        "id": "vGe0mkNGzzTf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully Connected Layers\n",
        "\n",
        "flatten = Flatten()(res50.output)\n",
        "\n",
        "dense = Dense(512, activation = 'relu')(flatten)\n",
        "dense = Dropout(0.5)(dense)\n",
        "dense = Dense(128, activation = 'relu')(dense)\n",
        "dense = Dropout(0.3)(dense)\n",
        "\n",
        "# Output Layer\n",
        "prediction = Dense(1, activation = 'sigmoid')(dense)"
      ],
      "metadata": {
        "id": "1otdqJNhz2Hd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Fully Connected Layers\n",
        "\n",
        "flatten = Flatten()(res50.output)\n",
        "\n",
        "dense = Dense(512, activation = 'relu')(flatten)\n",
        "dense = Dropout(0.5)(dense)\n",
        "dense = Dense(128, activation = 'relu')(dense)\n",
        "dense = Dropout(0.3)(dense)\n",
        "\n",
        "# Output Layer\n",
        "prediction = Dense(1, activation = 'sigmoid')(dense)"
      ],
      "metadata": {
        "id": "pygqgfswz8Ap"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1 = Model(inputs = res50.input, outputs = prediction)"
      ],
      "metadata": {
        "id": "wehBxcf7z_bO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.summary()#summary of model"
      ],
      "metadata": {
        "id": "wo1w6K6Vz_fR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "W5t6j7cR0E-i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import EarlyStopping"
      ],
      "metadata": {
        "id": "HHWxBWTk0FBt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=3,  # Number of epochs with no improvement after which training will be stopped\n",
        "    restore_best_weights=True\n",
        ")"
      ],
      "metadata": {
        "id": "qZPVloAd0FG4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history1 = model1.fit(\n",
        "    train_generator,\n",
        "    epochs=15,\n",
        "    validation_data=validation_generator,\n",
        "    callbacks=[early_stopping],\n",
        "\n",
        ")"
      ],
      "metadata": {
        "id": "6U0z8NVr0FLG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_results = model1.evaluate(validation_generator)\n",
        "print(f\"Test Loss: {test_results[0]}, Test Accuracy: {test_results[1]}\")"
      ],
      "metadata": {
        "id": "N9MHFHr-0cu5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
        "\n",
        "y_true = validation_generator.classes  # True labels\n",
        "y_pred_prob = model1.predict(validation_generator)  # Predicted probabilities\n",
        "\n",
        "# Convert probabilities to class labels\n",
        "y_pred = (y_pred_prob > 0.5).astype(int)  # Adjust threshold as needed\n",
        "\n",
        "# Calculate metrics\n",
        "accuracy = accuracy_score(y_true, y_pred)\n",
        "precision = precision_score(y_true, y_pred)\n",
        "recall = recall_score(y_true, y_pred)\n",
        "f1 = f1_score(y_true, y_pred)\n",
        "\n",
        "# Confusion Matrix\n",
        "conf_matrix = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy)\n",
        "print(\"Validation Precision:\", precision)\n",
        "print(\"Validation Recall:\", recall)\n",
        "print(\"Validation F1 Score:\", f1)\n",
        "\n",
        "print(\"\\nConfusion Matrix:\")\n",
        "print(conf_matrix)"
      ],
      "metadata": {
        "id": "u-ovTGWf0FOt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def cov():\n",
        "\n",
        "    input_image_path =input()\n",
        "    input_image = cv2.imread(input_image_path)\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    # cv2.imshow(\"Image\",input_image)\n",
        "    input_image_resized = cv2.resize(input_image, (180,180))\n",
        "\n",
        "    input_image_scaled = input_image_resized/255\n",
        "\n",
        "    input_image_reshaped = np.reshape(input_image_scaled, [1,180,180,3])\n",
        "\n",
        "    input_prediction = model1.predict(input_image_reshaped)\n",
        "\n",
        "    print(input_prediction)\n",
        "    if input_prediction>0.5:\n",
        "        print(\"Non-covid\")\n",
        "    else:\n",
        "        print(\"covid\")"
      ],
      "metadata": {
        "id": "o_zCzb7S0FYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling a function\n",
        "cov()"
      ],
      "metadata": {
        "id": "untKCegb0mPa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#calling a function\n",
        "cov()"
      ],
      "metadata": {
        "id": "gSvvGWPs0mi4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model1.save(\"Ct_Scan_Covid.h5\")"
      ],
      "metadata": {
        "id": "aNGuMQj103Fu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# library to load the model\n",
        "from tensorflow.keras.models import load_model"
      ],
      "metadata": {
        "id": "cuL91inb03JX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_model = load_model('/kaggle/working/Ct_Scan_Covid.h5')"
      ],
      "metadata": {
        "id": "3q3Iao-L03MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "def saved_model():\n",
        "\n",
        "    input_image_path =input()\n",
        "    input_image = cv2.imread(input_image_path)\n",
        "\n",
        "    plt.imshow(cv2.cvtColor(input_image, cv2.COLOR_BGR2RGB))\n",
        "    plt.axis('off')\n",
        "    plt.show()\n",
        "    # cv2.imshow(\"Image\",input_image)\n",
        "    input_image_resized = cv2.resize(input_image, (180,180))\n",
        "\n",
        "    input_image_scaled = input_image_resized/255\n",
        "\n",
        "    input_image_reshaped = np.reshape(input_image_scaled, [1,180,180,3])\n",
        "\n",
        "    input_prediction = s_model.predict(input_image_reshaped)\n",
        "\n",
        "    print(input_prediction)\n",
        "    if input_prediction>0.5:\n",
        "        print(\"Non-covid\")\n",
        "    else:\n",
        "        print(\"covid\")"
      ],
      "metadata": {
        "id": "VvHjgUTj07nK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model()"
      ],
      "metadata": {
        "id": "4MchtmBg07u8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SnY_FwhP07yX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0IkvSzA9076f"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}